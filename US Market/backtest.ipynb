{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2zX7ZxNyFQ"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\Courses\\AI\\Project\\paper\\venv_finrl\\Lib\\site-packages\\pyfolio\\pos.py:25: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "import statistics \n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "%matplotlib inline\n",
        "from FinRL.finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from FinRL.finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from FinRL.finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from FinRL.finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
        "from FinRL.finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_account_value = pd.read_csv('saved_result_us/df_account_value.csv', index_col=0)\n",
        "df_account_value_a2c = pd.read_csv('results/df_account_value_a2c.csv', index_col=0)\n",
        "df_account_value_ppo = pd.read_csv('results/df_account_value_ppo.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzkr9yv-AdV_",
        "outputId": "ab0971b8-10b0-4fb1-a151-71a1de89cdf2",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Backtest Results===========\n",
            "Annual return         -0.030872\n",
            "Cumulative returns    -0.124774\n",
            "Annual volatility      0.140338\n",
            "Sharpe ratio          -0.152972\n",
            "Calmar ratio          -0.094111\n",
            "Stability              0.250191\n",
            "Max drawdown          -0.328035\n",
            "Omega ratio            0.970788\n",
            "Sortino ratio         -0.196381\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.797249\n",
            "Daily value at risk   -0.017766\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Backtest Results===========\n",
            "Annual return          0.070592\n",
            "Cumulative returns     0.344637\n",
            "Annual volatility      0.166261\n",
            "Sharpe ratio           0.494156\n",
            "Calmar ratio           0.252858\n",
            "Stability              0.755332\n",
            "Max drawdown          -0.279174\n",
            "Omega ratio            1.101792\n",
            "Sortino ratio          0.676185\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.908182\n",
            "Daily value at risk   -0.020621\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value_ppo)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "# ==============Get Backtest Results===========\n",
        "# Annual return               0.379725\n",
        "# Cumulative returns          0.083797\n",
        "# Annual volatility      338567.947564\n",
        "# Sharpe ratio                2.017211\n",
        "# Calmar ratio                0.379725\n",
        "# Stability                   0.324152\n",
        "# Max drawdown               -1.000000\n",
        "# Omega ratio             22751.286315\n",
        "# Sortino ratio          155782.345252\n",
        "# Skew                             NaN\n",
        "# Kurtosis                         NaN\n",
        "# Tail ratio                  9.187028\n",
        "# Daily value at risk    -39945.381418"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Backtest Results===========\n",
            "Annual return         -0.004785\n",
            "Cumulative returns    -0.020606\n",
            "Annual volatility      0.173362\n",
            "Sharpe ratio           0.059808\n",
            "Calmar ratio          -0.012311\n",
            "Stability              0.334636\n",
            "Max drawdown          -0.388637\n",
            "Omega ratio            1.012160\n",
            "Sortino ratio          0.077931\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.864949\n",
            "Daily value at risk   -0.021800\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value_a2c)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "# ==============Get Backtest Results===========\n",
        "# Annual return               0.379725\n",
        "# Cumulative returns          0.083797\n",
        "# Annual volatility      338567.947564\n",
        "# Sharpe ratio                2.017211\n",
        "# Calmar ratio                0.379725\n",
        "# Stability                   0.324152\n",
        "# Max drawdown               -1.000000\n",
        "# Omega ratio             22751.286315\n",
        "# Sortino ratio          155782.345252\n",
        "# Skew                             NaN\n",
        "# Kurtosis                         NaN\n",
        "# Tail ratio                  9.187028\n",
        "# Daily value at risk    -39945.381418"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiHhM1YkoCel",
        "outputId": "c233f613-67a3-4882-8710-c1839247590e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Baseline Stats===========\n",
            "YF deprecation warning: set proxy via new config function: yf.set_config(proxy=proxy)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame:  (1070, 8)\n",
            "Annual return          0.044268\n",
            "Cumulative returns     0.201921\n",
            "Annual volatility      0.194809\n",
            "Sharpe ratio           0.320864\n",
            "Calmar ratio           0.119365\n",
            "Stability              0.838783\n",
            "Max drawdown          -0.370862\n",
            "Omega ratio            1.076707\n",
            "Sortino ratio          0.428540\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.874737\n",
            "Daily value at risk   -0.024296\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "df_dji_ = get_baseline(\n",
        "        ticker=\"^DJI\",\n",
        "        start = df_account_value.loc[0,'date'],\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(df_dji_, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhJ9whD75WTs",
        "outputId": "8ae25787-8400-4357-ecc0-af7538689cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_dji:              date           dji\n",
            "0     2015-12-31  1.000000e+06\n",
            "1     2016-01-04  9.841556e+05\n",
            "2     2016-01-05  9.847134e+05\n",
            "3     2016-01-06  9.702428e+05\n",
            "4     2016-01-07  9.477229e+05\n",
            "...          ...           ...\n",
            "1066  2020-03-27  1.241707e+06\n",
            "1067  2020-03-30  1.281345e+06\n",
            "1068  2020-03-31  1.257798e+06\n",
            "1069  2020-04-01  1.201921e+06\n",
            "1070  2020-04-02           NaN\n",
            "\n",
            "[1071 rows x 2 columns]\n",
            "df_dji:                       dji\n",
            "date                    \n",
            "2015-12-31  1.000000e+06\n",
            "2016-01-04  9.841556e+05\n",
            "2016-01-05  9.847134e+05\n",
            "2016-01-06  9.702428e+05\n",
            "2016-01-07  9.477229e+05\n",
            "...                  ...\n",
            "2020-03-27  1.241707e+06\n",
            "2020-03-30  1.281345e+06\n",
            "2020-03-31  1.257798e+06\n",
            "2020-04-01  1.201921e+06\n",
            "2020-04-02           NaN\n",
            "\n",
            "[1071 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "df_dji = pd.DataFrame()\n",
        "df_dji['date'] = df_account_value['date']\n",
        "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * 1000000\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji.csv\")\n",
        "df_dji = df_dji.set_index(df_dji.columns[0])\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji+.csv\")\n",
        "\n",
        "df_account_value.to_csv('df_account_value.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Suru3h1jc"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StockData tickers: ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'CVX', 'DD', 'DIS', 'GE', 'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'KO', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PFE', 'PG', 'TRV', 'UNH', 'V', 'VZ', 'WMT', 'XOM']\n",
            "Number of tickers: 29\n",
            "arReturns shape: (1696, 29)\n",
            "covReturns shape: (29, 29)\n",
            "Cleaned weights keys: ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'CVX', 'DD', 'DIS', 'GE', 'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'KO', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PFE', 'PG', 'TRV', 'UNH', 'V', 'VZ', 'WMT', 'XOM']\n",
            "Number of weights: 29\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cvxpy as cp\n",
        "processed = pd.read_csv('processed.csv', index_col=0)\n",
        "stock_dimension = len(processed.tic.unique())\n",
        "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], \n",
        "                                 'ensemble': df_account_value['account_value']}).set_index('date')\n",
        "\n",
        "df_result_a2c = pd.DataFrame({'date': df_account_value_a2c['date'], \n",
        "                             'a2c': df_account_value_a2c['account_value']}).set_index('date')\n",
        "\n",
        "df_result_ppo = pd.DataFrame({'date': df_account_value_ppo['date'], \n",
        "                             'ppo': df_account_value_ppo['account_value']}).set_index('date')\n",
        "\n",
        "# Merge all DataFrames using their date index\n",
        "result = df_result_ensemble.join([df_result_ppo, df_result_a2c, df_dji])\n",
        "\n",
        "TRAIN_START_DATE = '2009-01-01'\n",
        "TRAIN_END_DATE = '2015-09-30'\n",
        "TEST_START_DATE = '2015-09-30'\n",
        "TEST_END_DATE = '2020-05-08'\n",
        "# Helper function to process dataframe for portfolio optimization\n",
        "def process_df_for_mvo(df):\n",
        "    df = df.sort_values(['date', 'tic'], ignore_index=True)[['date', 'tic', 'close']]\n",
        "    fst = df.iloc[0:stock_dimension, :]\n",
        "    tic = fst['tic'].tolist()\n",
        "\n",
        "    mvo = pd.DataFrame()\n",
        "    for k in range(len(tic)):\n",
        "        mvo[tic[k]] = 0\n",
        "\n",
        "    for i in range(df.shape[0] // stock_dimension):\n",
        "        n = df.iloc[i * stock_dimension : (i + 1) * stock_dimension, :]\n",
        "        date = n['date'].iloc[0]  # Use .iloc to ensure single date\n",
        "        mvo.loc[date] = n['close'].tolist()\n",
        "\n",
        "    return mvo\n",
        "\n",
        "# Helper function to compute stock returns (in decimal form)\n",
        "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
        "    StockReturn = np.zeros([Rows - 1, Columns])\n",
        "    for j in range(Columns):\n",
        "        for i in range(Rows - 1):\n",
        "            StockReturn[i, j] = (StockPrice[i + 1, j] - StockPrice[i, j]) / StockPrice[i, j]\n",
        "    return StockReturn\n",
        "\n",
        "# Assuming data_split, processed_full, TRAIN_START_DATE, TRAIN_END_DATE, TEST_START_DATE, TEST_END_DATE, and stock_dimension are defined\n",
        "train_mvo = data_split(processed, TRAIN_START_DATE, TRAIN_END_DATE).reset_index()\n",
        "trade_mvo = data_split(processed, TEST_START_DATE, TEST_END_DATE).reset_index()\n",
        "\n",
        "# Process data for training and trading periods\n",
        "StockData = process_df_for_mvo(train_mvo)\n",
        "TradeData = process_df_for_mvo(trade_mvo)\n",
        "\n",
        "# Get tickers\n",
        "tickers = StockData.columns.tolist()\n",
        "print(\"StockData tickers:\", tickers)\n",
        "print(\"Number of tickers:\", len(tickers))\n",
        "\n",
        "# Compute asset returns\n",
        "arStockPrices = np.asarray(StockData)\n",
        "Rows, Cols = arStockPrices.shape\n",
        "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
        "print(\"arReturns shape:\", arReturns.shape)\n",
        "\n",
        "# Compute mean returns and covariance matrix\n",
        "meanReturns = np.mean(arReturns, axis=0)\n",
        "covReturns = np.cov(arReturns, rowvar=False)\n",
        "print(\"covReturns shape:\", covReturns.shape)\n",
        "\n",
        "# Check for NaN in covariance matrix\n",
        "if np.any(np.isnan(covReturns)):\n",
        "    print(\"Warning: covReturns contains NaN values. Check input data for missing or invalid prices.\")\n",
        "    raise ValueError(\"NaN values in covariance matrix\")\n",
        "\n",
        "# Convert meanReturns and covReturns to pandas with tickers\n",
        "meanReturns = pd.Series(meanReturns, index=tickers)\n",
        "covReturns = pd.DataFrame(covReturns, index=tickers, columns=tickers)\n",
        "\n",
        "# ── Replace pypfopt EfficientFrontier with CVXPY-based Min Variance ─────────────\n",
        "# 1) Extract Σ (covariance matrix) in the correct ticker order\n",
        "Σ = covReturns.loc[tickers, tickers].to_numpy()  # shape (n, n)\n",
        "n = len(tickers)\n",
        "\n",
        "# 2) Define CVXPY variable\n",
        "w = cp.Variable(n)\n",
        "\n",
        "# 3) Define objective: minimize w^T Σ w\n",
        "objective = cp.Minimize(cp.quad_form(w, Σ))\n",
        "\n",
        "# 4) Define constraints: sum(w) == 1, 0 <= w_i <= 0.5\n",
        "constraints = [\n",
        "    cp.sum(w) == 1,\n",
        "    w >= 0,\n",
        "    w <= 0.5\n",
        "]\n",
        "\n",
        "# 5) Formulate and solve the problem\n",
        "prob = cp.Problem(objective, constraints)\n",
        "prob.solve(solver=cp.SCS)\n",
        "\n",
        "# 6) Check solver status\n",
        "if prob.status not in [\"optimal\", \"optimal_inaccurate\"]:\n",
        "    raise ValueError(f\"CVXPY did not find an optimal solution (status={prob.status})\")\n",
        "\n",
        "# 7) Extract raw weights and clean them (clamp negatives to zero, re-normalize)\n",
        "raw_weights = w.value\n",
        "cleaned = np.maximum(raw_weights, 0)\n",
        "cleaned = cleaned / cleaned.sum()\n",
        "\n",
        "# 8) Map cleaned weights back into a dict keyed by ticker\n",
        "cleaned_weights_min_var = {tickers[i]: float(cleaned[i]) for i in range(n)}\n",
        "\n",
        "# Debug: Check weights\n",
        "print(\"Cleaned weights keys:\", list(cleaned_weights_min_var.keys()))\n",
        "print(\"Number of weights:\", len(cleaned_weights_min_var))\n",
        "\n",
        "# Verify ticker alignment\n",
        "missing_tickers = [tic for tic in tickers if tic not in cleaned_weights_min_var]\n",
        "if missing_tickers:\n",
        "    print(\"Error: Missing tickers in weights:\", missing_tickers)\n",
        "    raise KeyError(f\"Tickers {missing_tickers} not found in cleaned_weights_min_var\")\n",
        "\n",
        "# Compute dollar allocations ($1,000,000 total portfolio value)\n",
        "min_var_weights = np.array([1_000_000 * cleaned_weights_min_var[tic] for tic in tickers])\n",
        "\n",
        "# Compute number of shares based on last training period prices\n",
        "# (assuming fractional shares are allowed for backtesting)\n",
        "LastPrice = np.array([1 / p for p in StockData.tail(1).to_numpy()[0]])\n",
        "Initial_Portfolio_min_var = np.multiply(min_var_weights, LastPrice)\n",
        "\n",
        "# Calculate portfolio value over the trade period\n",
        "# Ensure TradeData columns align with `tickers` order\n",
        "TradeData = TradeData[tickers]\n",
        "Portfolio_Assets_min_var = TradeData @ Initial_Portfolio_min_var\n",
        "\n",
        "# Create DataFrame for Min Variance results\n",
        "df_account_value_min_var = pd.DataFrame({\n",
        "    'date': TradeData.index,\n",
        "    'account_value': Portfolio_Assets_min_var\n",
        "}).reset_index(drop=True)\n",
        "\n",
        "# Prepare result DataFrame for comparison\n",
        "df_result_min_var = pd.DataFrame({\n",
        "    'date': df_account_value_min_var['date'],\n",
        "    'min_var': df_account_value_min_var['account_value']\n",
        "}).set_index('date')\n",
        "\n",
        "# Assuming df_result_ensemble, df_result_ppo, df_result_a2c, and df_dji are defined\n",
        "# Merge all strategy results\n",
        "result = df_result_ensemble.join([df_result_ppo, df_result_a2c, df_result_min_var, df_dji], how='inner')\n",
        "\n",
        "# Calculate cumulative returns\n",
        "initial_ensemble = result['ensemble'].iloc[0]\n",
        "initial_ppo = result['ppo'].iloc[0]\n",
        "initial_a2c = result['a2c'].iloc[0]\n",
        "initial_min_var = result['min_var'].iloc[0]\n",
        "initial_dji = result['dji'].iloc[0]\n",
        "\n",
        "df_cumulative = pd.DataFrame({\n",
        "    'Ensemble': (result['ensemble'] / initial_ensemble - 1) * 100,\n",
        "    'PPO':      (result['ppo']      / initial_ppo      - 1) * 100,\n",
        "    'A2C':      (result['a2c']      / initial_a2c      - 1) * 100,\n",
        "    'Min Var':  (result['min_var']  / initial_min_var  - 1) * 100,\n",
        "    'DJI':      (result['dji']      / initial_dji      - 1) * 100\n",
        "}, index=result.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ensemble</th>\n",
              "      <th>PPO</th>\n",
              "      <th>A2C</th>\n",
              "      <th>Min Var</th>\n",
              "      <th>DJI</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-04</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-05</th>\n",
              "      <td>0.084962</td>\n",
              "      <td>-0.007047</td>\n",
              "      <td>-0.132477</td>\n",
              "      <td>1.075683</td>\n",
              "      <td>0.056684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-06</th>\n",
              "      <td>-1.122453</td>\n",
              "      <td>-0.278921</td>\n",
              "      <td>-1.781920</td>\n",
              "      <td>0.733778</td>\n",
              "      <td>-1.413672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-07</th>\n",
              "      <td>-2.921573</td>\n",
              "      <td>-1.095146</td>\n",
              "      <td>-4.536075</td>\n",
              "      <td>0.020763</td>\n",
              "      <td>-3.701919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-08</th>\n",
              "      <td>-3.933838</td>\n",
              "      <td>-1.645291</td>\n",
              "      <td>-5.710675</td>\n",
              "      <td>-1.042332</td>\n",
              "      <td>-4.679527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-27</th>\n",
              "      <td>-9.206046</td>\n",
              "      <td>25.213107</td>\n",
              "      <td>-11.538545</td>\n",
              "      <td>52.462749</td>\n",
              "      <td>26.169781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-30</th>\n",
              "      <td>-6.776664</td>\n",
              "      <td>25.823655</td>\n",
              "      <td>-9.234763</td>\n",
              "      <td>60.040820</td>\n",
              "      <td>30.197442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-31</th>\n",
              "      <td>-8.326808</td>\n",
              "      <td>24.906211</td>\n",
              "      <td>-11.278366</td>\n",
              "      <td>57.093221</td>\n",
              "      <td>27.804756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-01</th>\n",
              "      <td>-12.966479</td>\n",
              "      <td>22.607187</td>\n",
              "      <td>-15.567090</td>\n",
              "      <td>54.032060</td>\n",
              "      <td>22.127143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-02</th>\n",
              "      <td>-11.842261</td>\n",
              "      <td>23.591706</td>\n",
              "      <td>-13.146990</td>\n",
              "      <td>59.525856</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1070 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Ensemble        PPO        A2C    Min Var        DJI\n",
              "date                                                             \n",
              "2016-01-04   0.000000   0.000000   0.000000   0.000000   0.000000\n",
              "2016-01-05   0.084962  -0.007047  -0.132477   1.075683   0.056684\n",
              "2016-01-06  -1.122453  -0.278921  -1.781920   0.733778  -1.413672\n",
              "2016-01-07  -2.921573  -1.095146  -4.536075   0.020763  -3.701919\n",
              "2016-01-08  -3.933838  -1.645291  -5.710675  -1.042332  -4.679527\n",
              "...               ...        ...        ...        ...        ...\n",
              "2020-03-27  -9.206046  25.213107 -11.538545  52.462749  26.169781\n",
              "2020-03-30  -6.776664  25.823655  -9.234763  60.040820  30.197442\n",
              "2020-03-31  -8.326808  24.906211 -11.278366  57.093221  27.804756\n",
              "2020-04-01 -12.966479  22.607187 -15.567090  54.032060  22.127143\n",
              "2020-04-02 -11.842261  23.591706 -13.146990  59.525856        NaN\n",
              "\n",
              "[1070 rows x 5 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cumulative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\phung\\AppData\\Local\\Temp\\ipykernel_20444\\3962919286.py:37: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# … all your data-prep up through df_cumulative …\n",
        "# ensure the index is parsed as real timestamps\n",
        "df_cumulative.index = pd.to_datetime(df_cumulative.index)\n",
        "\n",
        "# Create a figure and axes explicitly\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Plot the cumulative returns (this draws your four lines exactly as before)\n",
        "df_cumulative.plot(ax=ax)\n",
        "\n",
        "# —— now override the default x-axis ticks & grid —— \n",
        "\n",
        "# 1. Major ticks every quarter (Jan, Apr, Jul, Oct)\n",
        "ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth=[1,4,7,10]))\n",
        "\n",
        "# 2. Format each tick as “Jan 4” on line 1, “2016” on line 2\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d\\n%Y'))\n",
        "\n",
        "# 3. Draw vertical gridlines at those quarter-points, plus horizontal at y-majors\n",
        "ax.grid(axis='x', which='major', linestyle='--', linewidth=0.5)\n",
        "ax.grid(axis='y', which='major', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# 4. Tweak tick label alignment\n",
        "plt.setp(ax.get_xticklabels(), rotation=0, ha='center')\n",
        "\n",
        "# —— finish off your labels/legend/title exactly as before —— \n",
        "\n",
        "ax.set_title('Cumulative Return Comparison of Trading Strategies vith Transaction Cost')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Cumulative Return (%)')\n",
        "ax.legend(['Ensemble', 'PPO', 'A2C', 'DJIA', 'Min var'])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('cumulative_return_newa2cppo.pdf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            turbulence\n",
            "date                  \n",
            "2012-10-23   45.885601\n",
            "2015-02-06   47.250387\n",
            "2011-10-12   43.087721\n",
            "2015-11-05   18.984310\n",
            "2016-04-13   47.696167\n",
            "2017-01-18   21.315345\n",
            "2018-08-16   70.918119\n",
            "2017-05-30   15.902929\n",
            "2012-05-25   12.924034\n",
            "2015-12-04   26.559442\n",
            "2016-09-09   32.125054\n",
            "2016-11-18   16.457930\n",
            "2011-01-25   62.963613\n",
            "2010-12-03    7.375143\n",
            "2014-07-17   30.591824\n",
            "2013-07-16   25.284485\n",
            "2013-06-12   20.064635\n",
            "2011-03-10   38.580225\n",
            "2011-05-31   16.113154\n",
            "2016-04-20  104.306893\n"
          ]
        }
      ],
      "source": [
        "# assuming `processed` has columns ['date','tic',...,'turbulence']\n",
        "turb_per_date = (\n",
        "    processed[['date','turbulence']]\n",
        "    .drop_duplicates('date')\n",
        "    .set_index('date')\n",
        "    .sort_index()\n",
        ")\n",
        "\n",
        "# now turb_per_date is one row per date:\n",
        "print(turb_per_date.sample(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# … your data prep up through df_cumulative …\n",
        "\n",
        "start, end = \"2020-01-02\", \"2020-03-30\"\n",
        "df_win = df_cumulative.loc[start:end]\n",
        "\n",
        "# Make turbulence a Series, not DataFrame\n",
        "turb_win = turb_per_date['turbulence'].loc[start:end]\n",
        "turb_win.index = pd.to_datetime(turb_win.index)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "df_win.plot(ax=ax, linewidth=1.5)\n",
        "ax.set_xlim(start, end)\n",
        "\n",
        "ax.xaxis.set_major_locator(mdates.DayLocator(interval=9))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
        "ax.grid(axis='x', which='major', linestyle='--', linewidth=0.5)\n",
        "ax.grid(axis='y', which='major', linestyle='--', linewidth=0.5)\n",
        "\n",
        "ax.set_ylabel('Cumulative Return (%)')\n",
        "ax.legend(['Ensemble', 'PPO', 'A2C', 'DJIA', 'Min var'])\n",
        "\n",
        "# Twin axis — now turb_win is a Series\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(turb_win.index, turb_win.values,\n",
        "         color='red', linestyle='--', linewidth=2,\n",
        "         label='Turbulence Index')\n",
        "ax2.set_ylabel('Turbulence Index')\n",
        "\n",
        "# This will now be a single float\n",
        "ax2.set_ylim(0, turb_win.max() * 1.1)\n",
        "\n",
        "# Merge legends\n",
        "lines, labs = ax.get_legend_handles_labels()\n",
        "l2, la2 = ax2.get_legend_handles_labels()\n",
        "ax.legend(lines + l2, labs + la2, loc='lower left', frameon=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('turbulence_newa2cppo.pdf')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_finrl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
